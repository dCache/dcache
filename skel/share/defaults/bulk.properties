#  -----------------------------------------------------------------------
#     Default values for bulk service
#  -----------------------------------------------------------------------
@DEFAULTS_HEADER@

#  ---- Cell name of the bulk service(s)
#
bulk.cell.name=${dcache.service.bulk}

bulk.cell.consume=${bulk.cell.name}
bulk.cell.subscribe=${bulk.pool-monitor.topic}

#  ----- Whether the service is replicable
#
#   Any service in dCache can have several instances as long as these
#   represent separate logical services. Some services can have several
#   instances representing the same logical service, providing some
#   degree of fault tolerance and load balancing. Such services are said
#   to be replicable.
#
#   Instances of a logical service share the same service name, and it is
#   important that the configuration for such instances is synchronized.
#
#   This property indicates if this service is replicable.
#
(immutable)bulk.cell.replicable = false

bulk.ping.cell.name=${dcache.service.bulk.ping}
bulk.ping.cell.consume=${bulk.ping.cell.name}

#  ---- Main bulk area
#
bulk.dir=@dcache.paths.bulk@

#  ---- For internal use only.
#
(immutable)bulk.limits.job-execution-threads=${bulk.limits.max-running-jobs}

#  ---- For internal use only.
#
(immutable)bulk.limits.job-cleanup-threads=${bulk.limits.max-cleanup-jobs}

#  ---- For internal use only.
#
(immutable)bulk.limits.job-callback-threads=${bulk.limits.max-callbacks}

#  ---- Number of jobs which can run concurrently.  This
#       determines the number of threads provided for job execution.
#       Note: by 'job' we refer to the processing of a single target
#       (path), be it a file or a directory.
#
bulk.limits.max-running-jobs=100

#  ---- Number of jobs (see above) which can be queued or waiting.
#
#       This number should be calibrated according to available memory as
#       follows:
#
#       Given approximately 1KB of memory for a job, multiply this figure
#       by 2, and you will have a minimal memory requirement for just the
#       queues in which jobs could be present for a longer period of time.
#       Thus the default value given below means 2GB (in which
#       case the domain JVM should be given somewhat more than 2GB
#       of heap memory).
#
#       While the queues are not strictly bounded (so as not to block), the
#       risk of an out-of-memory error is mitigated by computing the maximum
#       number of requests that can be run as
#       max-queued-jobs/avg-jobs-per-request.
#
bulk.limits.max-queued-jobs=1000000

#  ---- Estimate of the number of jobs on average generated by a request.
#
#       Used in conjunction with the max-queued-jobs property to compute
#       whether a new request can be activated.
#
#       NOTE:  This figure will probably need to be adjusted depending on
#       the size of the namespace and the average number of
#       files per directory.  Requests which could entail a much greater
#       number of target paths may suggest the need to adjust upwards
#       the max-queued-jobs value and to allocate more heap space to the
#       domain JVM in order to increase request throughput.
#
bulk.limits.avg-jobs-per-request=50000

#  ---- Number of cleanup tasks which can run concurrently
#
bulk.limits.max-cleanup-jobs=20

#  ---- Number of message callbacks for synchronous jobs that can run concurrently
#
bulk.limits.max-callbacks=20

#  ---- Prevents users from monopolizing the service.
#       The limit is in terms of the number of submitted requests
#       which have not yet completed (but not necessarily cleared).
#
bulk.limits.max-requests-per-user=5

#  ---- Number of threads available for incoming request processing.
#
bulk.limits.message-handler-threads=10

#  ---- If a user requests a delay before a completed request is cleared,
#       it is scheduled by an executor with this number of available threads.
#
bulk.limits.request-store-clear-threads=5

#  ---- Interval of inactivity by the queue consumer if not signalled
#       internally (as for instance when a job completes).
#
#       Given the latency (time-to-completion) of bulk operations,
#       the queue consumer need not wake up on its own frequently.
#
bulk.limits.queue-sweep-interval=3
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)bulk.limits.queue-sweep-interval.unit=MINUTES

#  ---- Requests (but not individual tasks/jobs) are stored on disk so that
#       they survive restarts.
#
bulk.store.request-store-dir=${bulk.dir}/requests

# ---- Endpoint for contacting pnfs manager.
#
bulk.service.pnfsmanager=${dcache.service.pnfsmanager}

# ---- How long to wait for a response from the pnfs manager.
#
bulk.service.pnfsmanager.timeout=1
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)bulk.service.pnfsmanager.timeout.unit=MINUTES

# ---- Endpoint for contacting pin manager.
#
bulk.service.pinmanager=${dcache.service.pinmanager}

# ---- How long to wait for a response from the pin manager.
#
bulk.service.pinmanager.timeout=1
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)bulk.service.pinmanager.timeout.unit=MINUTES

# ---- Endpoint for contacting pool manager.
#
bulk.service.poolmanager=${dcache.service.poolmanager}

# ---- How long to wait for a response from the pool manager.
#
bulk.service.poolmanager.timeout=1
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)bulk.service.poolmanager.timeout.unit=MINUTES

# ---- Endpoint for the 'ping' service (testing only).
#
bulk.service.ping=${dcache.service.ping}

# ---- How long to wait for a response from the ping service.
#      When using this (test) service, this value needs to be set to something
#      slightly greater than the maximum wait value on the service.
#
bulk.service.ping.timeout=5
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)bulk.service.ping.timeout.unit=MINUTES

# Topic on which to expect pool monitor updates
#
bulk.pool-monitor.topic=${dcache.pool-monitor.topic}
