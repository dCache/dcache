#
# dCache - http://www.dcache.org/
#
# Copyright (C) 2016 Deutsches Elektronen-Synchrotron
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#

# -----------------------------------------------------------------------
#    Default values for srm
# -----------------------------------------------------------------------
@DEFAULTS_HEADER@

#  ---- Name of the service
#
#   This is the logical name of the service. The service name is usually
#   the name other service use to reach this service.
#
srmmanager.cell.service = ${dcache.queue.srmmanager}

# ---- Cell names
#
srmmanager.cell.name = ${dcache.queue.srmmanager}

#  ----- Whether the service is replicable
#
#   Any service in dCache can have several instances as long as these
#   represent separate logical services. Some services can have several
#   instances representing the same logical service, providing some
#   degree of fault tolerance and load balancing. Such services are said
#   to be replicable.
#
#   Instances of a logical service share the same service name, and it is
#   important that the configuration for such instances is synchronized.
#
#   This property indicates if this service is replicable.
#
#   Multiple instances should have separate SRM databases.
#
(immutable)srmmanager.cell.replicable = true

#  ---- Named queues to consume from
#
#   A service can consume messages from named queues. Other service can
#   write messages to such queues. A named queue has an unqualified cell
#   address, that is, an address without a domain name.
#
#   This property contains a comma separated list of named queues to
#   consume from.
#
srmmanager.cell.consume=${srmmanager.cell.service}

#  ---- Topics to which the service subscribes
#
#   A service can subscribe to messages on topics. Other services can
#   write messages to such topics and all subscribers receive such
#   messages. A topic has an unqualified cell address, that is, an
#   address without a domain name.
#
#   This property contains a comma separated list of topics to
#   subscribe to.
#
srmmanager.cell.subscribe = ${srmmanager.loginbroker.update-topic},${srmmanager.pool-monitor.topic},${dcache.topic.watched}

# Cell message processing limits
srmmanager.cell.max-message-threads = 500
srmmanager.cell.max-messages-queued = 1000

#  ---- TCP Port
#
#  The port SRM frontends listen on for GSI-based communication.  GSI is an
#  encrypted transport commonly used in grid communication.  It is
#  similar to SSL but incompatible.
#
srmmanager.net.port = 8443
#
#  The port SRM frontends listen on for SSL-based communication.  SSL is an
#  industry standard encryption transport.
#
srmmanager.net.ssl-port = 8445

# ---- Host name of srm service
#
# For certain operations srm needs to know its public host name.  The
# srmmanager.net.host property can be used to override the default value.  If
# this value is not set, the value is detected automatically and it is
# equivalent to the output of the unix hostname program.
#
srmmanager.net.host = ${host.fqdn}


# ---- Host names of srm services in this deployment
#
# A host part of the source url (surl) is used to determine if the
# surl references file in this storage system.  In case of the copy
# operation, srm needs to be able to dinstinguish between the local
# surl and the remote one.  Also srm needs to refuse to perform
# operations on non local srm urls.  The srmmanager.net.local-hosts property
# value is a comma separated list of hosts that will be considered
# local by this srm service.  This parameter might need to be defined
# as a list because in case of the multihomed or distributed server it
# may have more than one network name.  If srmmanager.net.local-host is not
# specified, srmmanager.net.host will be used.
#
srmmanager.net.local-hosts=${srmmanager.net.host}


# ---- Client side transport layer encryption
#
# The security transport to use when contacting remote SRM instances.  GSI
# (Grid Security Infrastructure) is the commonly deployed protocol, but SSL
# is the industrial standard.  This property is only used for third-party
# copies (srmCopy).
#
(one-of?SSL|GSI)srmmanager.client-transport = GSI

# ---- Unique identifier amongst all instances of a logical srmmanager service
#
# Database records are tagged with an identifier derived from this value. If a logical
# srmmanager service is replicated with a shared database, each instance must have a
# unique value for this property.
#
srmmanager.scheduler-id=SRM-${host.name}

# ---- Database host name
#
# See dcache.db.host for details.
#
srmmanager.db.host = ${dcache.db.host}

# ---- Database name
srmmanager.db.name = srm


# ---- Database user name
srmmanager.db.user = ${dcache.db.user}

# ---- Database password
srmmanager.db.password = ${dcache.db.password}

# ---- Database password file
srmmanager.db.password.file = ${dcache.db.password.file}

# ---- Database JDBC URL
srmmanager.db.url = jdbc:postgresql://${srmmanager.db.host}/${srmmanager.db.name}?targetServerType=master

#
# The maximum number of concurrent database connections.
#
srmmanager.db.connections.max = 50

#
# The minimum number of idle database connections.
#
srmmanager.db.connections.idle = 1

#  ---- Whether to manage the database schema automatically during startup
#
# If set to 'false' then the "dcache database update" command must be used to
# check if database schema needs to be updated and apply any necessary changes.
(one-of?true|false|${dcache.db.schema.auto})srmmanager.db.schema.auto=${dcache.db.schema.auto}

# Liquibase schema definition
srmmanager.db.schema.changelog=org/dcache/srm/request/sql/srm.changelog-master.xml


# ---- TCP streams to use for GridFTP transfer
#
#   The number of concurrent TCP streams used by srmCopy controlled
#   GridFTP transfers.
#
srmmanager.limits.parallel-streams = 10

# ---- Timeout of the external srmCopy script
#
#   Timeout in seconds, how long to wait for the completion of the
#   transfer via external client, should the external client be used
#   for the MSS to MSS transfers.
#
srmmanager.limits.external-copy-script.timeout = 3600
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)\
srmmanager.limits.external-copy-script.timeout.unit=SECONDS


# ---- Buffer size used for srmCopy transfer
#
#   Specified in bytes.
#
srmmanager.limits.transfer-buffer.size = 1048576

# ---- TCP buffer size used for srmCopy transfer
#
#   Specified in bytes.
#
srmmanager.limits.transfer-tcp-buffer.size = 1048576

# ---- Controls debug functionality of the external srmCopy script
#
(one-of?true|false)srmmanager.enable.external-copy-script.debug = true

# ---- Parameters for schedulable SRM requests
#
# The SRM specification allows some request types to be processed
# asynchronously. Rather than waiting for request processing to
# complete before getting a reply, the client receives a preliminary
# reply stating that the request is accepted with instructions to
# ask back for the result later. The SRM specification allows this
# mode of operation for the following requests:
#
#  o srmReserveSpace
#  o srmUpdateSpace
#  o srmChangeSpaceForFiles
#  o srmLs
#  o srmPrepareToGet
#  o srmPrepareToPut
#  o srmCopy
#  o srmBringOnline
#
# Except for srmUpdateSpace and srmChangeSpaceForFiles, dCache supports
# asynchronous processing for all these requests.
#
# These requests share a common lifecycle:
#
#  o SRM_REQUEST_QUEUED
#
#    The request is queued for processing. dCache is currently not processing
#    the request.
#
#  o SRM_REQUEST_INPROGRESS
#
#    dCache is processing the request.
#
#  o SRM_FILE_PINNED / SRM_SPACE_AVAILABLE
#
#    For srmPrepareToGet and srmPrepareToPut these states indicate
#    that a transfer URL has been prepared and the client is expected
#    to transfer the file.
#
#  o SRM_SUCCESS / SRM_FAILURE / SRM_RELEASED / SRM_ABORTED
#
#    Request has completed and is no longer active
#
# This lifecycle is controlled by the SRM request scheduler. A separate
# scheduler exists for each request type, allowing limits to be configured
# individually.
#
# The SRM specification supports bulk operations for the following requests:
#
#  o srmLs
#  o srmPrepareToGet
#  o srmPrepareToPut
#  o srmCopy
#  o srmBringOnline
#  o srmRm
#
# A single client request may apply to a large number of files. Internally,
# dCache treats each file in a schedulable bulk request individually. To be
# precise, the scheduling described above does not apply to the entire SRM
# request, but to each site URL in the request. This is also true for the
# configuration properties described below.
#
# srmRm isn't a schedulable request and thus the discussion above doesn't
# apply to it.


# ---- Maximum number of requests allowed
#
# This is the maximum number requests allowed of any given
# request type. Once the limit is reached, new requests will fail
# immediately rather than being queued.
#
# Any request that is not finished counts towards this limit. That is, all
# requests in one of the following states: SRM_REQUEST_QUEUED,
# SRM_REQUEST_INPROGRESS, SRM_FILE_PINNED and SRM_SPACE_AVAILABLE.
#
srmmanager.request.max-requests = 50000
srmmanager.request.get.max-requests = ${srmmanager.request.max-requests}
srmmanager.request.bring-online.max-requests = ${srmmanager.request.max-requests}
srmmanager.request.put.max-requests = ${srmmanager.request.max-requests}
srmmanager.request.copy.max-requests = ${srmmanager.request.max-requests}
srmmanager.request.ls.max-requests = ${srmmanager.request.max-requests}
srmmanager.request.reserve-space.max-requests = ${srmmanager.request.max-requests}


# ---- Maximum number of requests in progress
#
# Maximum number of requests to process concurrently of any given request type.
# This limits the number of SRM_REQUEST_INPROGRESS requests. Once the limit is
# reached, new requests will queue. Requests for which a TURL was already
# computed do not count towards this limit even if their state may be reported
# as SRM_REQUEST_INPROGRESS.
#
# The setting is a good measure of how much load the SRM can induce directly
# on other services in dCache, such as pnfs manager and pin manager.
#
# Notably, this setting limits the number of files that can be brought online
# simultaneously for get and bring-online requests, and the number of concurrent
# srmCopy transfers.
#
# The setting does NOT limit the number of concurrent upload and downloads. In
# SRM, srmPrepareToPut and srmPrepareToGet do not actually transfer a file: They
# prepare a transfer URL so that the client can transfer a file. Once the transfer
# URL has been prepared, the requests are no longer considered in progress (see
# srmmanager.request.max-transfers).
#
srmmanager.request.get.max-inprogress = 1000
srmmanager.request.bring-online.max-inprogress = 10000
srmmanager.request.copy.max-inprogress = 1000
srmmanager.request.put.max-inprogress = 50
srmmanager.request.ls.max-inprogress = 50
srmmanager.request.reserve-space.max-inprogress = 10

# ---- Number of simultaneous transfer URLs
#
# This limits the number of TURLs to hand out to clients. If this limit is reached,
# additional requests will be queued after having been prepared.
#
# Note that clients may not actually transfer the file right after receiving a
# TURL. Many advanced clients check out TURLs ahead of time and queue transfers
# to and from those TURLs. Thus the actual number of transfers observed on dCache
# doors may be lower than the number TURLs handed out to the client.
#
# Note that this setting does not apply to srmCopy requests. Such requests do
# not have a TURL as the transfer is done by dCache and not by the client. To
# control the number of concurrent copies use srmmanager.request.copy.max-inprogress or
# the settings of the transfermanagers service.
#
srmmanager.request.max-transfers=50000

srmmanager.request.get.max-transfers = ${srmmanager.request.max-transfers}

srmmanager.request.put.max-transfers = ${srmmanager.request.max-transfers}


# ---- Request discriminator
#
# A discriminator identifies a request as coming from a particular user or group of
# users: a party.  Requests with the same discriminator value come from the same party.
#
# Discriminators are typically used by fair-share schedulers when deciding which requests
# should be grouped together.  Such schedulers maintain some degree of fairness between
# requests from different parties (requests with distinct discriminator values) and not
# between requests from the same party.
#
# Discriminators are provided by plugins implementing the JobDiscriminator SPI.  Several
# such plugins ship with dCache:
#
#   uid    The request submitter's UID.
#
#   gid    The request submitter's primary GID.
#
#   dn     The request submitter's distinguished name.
#
#   fqan   The request submitter's primary FQAN.
#
#   user   The request submitter's mapped user name.
#
#   vo     The request submitter's VO association as extracted from the primary FQAN.
#
srmmanager.plugins.discriminator=dn


# ---- Request scheduling strategy
#
# Strategy for how to schedule schedulable SRM requests. The strategy controls in which order
# SRM requests transition from the SRM_REQUEST_QUEUED state to SRM_REQUEST_INPROGRESS. Once
# the max-inprogress limit for a specific type of requests is reached, subsequent requests are
# queued and the scheduling strategy controls the order in which these requests are processed.
#
# The strategy is pluggable and third party plugins can add new strategies by implementing
# scheduling strategy SPI. Several plugins ship with dCache:
#
#   fifo    First in, first out. Requests are processed in arrival order. Individual users
#           may monopolise the SRM through issuing many requests or issuing long-lasting
#           requests.
#
#   lifo    Last in, first out. The last request to arrive is processed first. In contrast to
#           fifo, this policy is not fair. Under load spikes, some requests will observe longer
#           response times, while others appear fast.
#
#           Lifo does however tend to be more robust in overload scenarios because it processes
#           the requests for which the client is least likely to time out first. In other words,
#           it can maintain maximum request rate, while fifo in some scenarios can enter a
#           live-lock in which all resources are spent on processing requests for which the
#           client subsequently times out.
#
#   throughput-fair-share
#
#           Round robin scheduler providing fair sharing of the request rate. E.g. if two
#           parties have requests queued, requests are scheduled in alternating order. Does
#           not prevent that one party may monopolise the system by submitting long running
#           requests while the other party submits requests that finish quickly.
#
#           A configurable discriminator defines the grouping between which to provide a
#           fair share.
#
#   inprogress-fair-share
#
#           Least-inprogress-requests-first scheduler providing fair sharing of the inprogress
#           slots. E.g. if two parties have requests queued, the party with the least inprogress
#           requests is the one whose request will be started. If one party submits long running
#           requests, that party will effectively be penalized by having a lower request rate.
#
#           A configurable discriminator defines the grouping between which to provide a
#           fair share.
#
srmmanager.plugins.scheduler = inprogress-fair-share

# Configuration of the inprogress fair share strategy.
(prefix)srmmanager.scheduler.inprogress-fair-share = Configuration for the in progress fair share scheduling strategy

# Discriminator for the inprogress fair share strategy.
srmmanager.scheduler.inprogress-fair-share!discriminator = ${srmmanager.plugins.discriminator}

# Configuration of the throughput fair share strategy.
(prefix)srmmanager.scheduler.throughput-fair-share = Configuration for the throughput fair share scheduling strategy

# Discriminator for the throughput fair share strategy.
srmmanager.scheduler.throughput-fair-share!discriminator = ${srmmanager.plugins.discriminator}


# ---- Request transfer strategy
#
# srmPrepareToPut and srmPrepareToGet requests enter the READY state when the TURL is handed
# out to the client. If the request is processed asynchronously (client is polling for the result),
# the request stays in the RQUEUED state until the client queries the result.
#
# A transfer strategy plugin has the ability to prevent the transition from the RQUEUED to READY
# state. A plugin may allow the number of concurrent transfers to be limited, or may provide
# some fair-share between parties.
#
# Two plugins ship with dCache:
#
#     first-come-first-served
#
#         The maximum number of requests in the READY state is limited by
#         srmmanager.request.*.max-transfers, but otherwise TURLs are handed out to
#         whomever comes first.
#
#     fair-share
#
#         The maximum number of requests in the READY state is limited by
#         srmmanager.request.*.max-transfers, but slots are kept free such that each party with
#         requests in RQUEUED will receive its fair share.
#
#           A configurable discriminator defines the grouping between which to provide a
#           fair share.
#
srmmanager.plugins.transfer = fair-share

# Configuration of the fair share ready strategy.
(prefix)srmmanager.transfer.fair-share = Configuration for the fair share transfer strategy

# Discriminator for the fair share transfer strategy.
srmmanager.transfer.fair-share!discriminator = ${srmmanager.plugins.discriminator}

# Configuration of the max ready strategy.
(prefix)srmmanager.transfer.first-come-first-served = Configuration for the first come first serve transfer strategy



# ---- Delay until requests are processed asynchronously
#
# Schedulable SRM requests may be processed synchronously or asynchronously, at
# the server's discretion.  dCache can start to process such requests synchronously
# and, if this is taking too long, reply asynchronously and continue to work on the
# operation background. While in synchronous mode, a webserver thread is blocked
# waiting for the result (see srmmanager.limits.jetty.threads.min and
# srmmanager.limits.jetty.threads.max).
#
# This setting specifies the time after which requests are handled asynchronously.
# Set to 'infinity' to disable asynchronous processing.
#
# Asynchronous processing avoids holding TCP connections to the server while
# the request is processed, but at the expense of the client periodically polling
# the status, thus increasing the perceived request processing time.
#
srmmanager.request.switch-to-async-mode-delay = 1000
(one-of?MILLISECONDS|SECONDS|MINUTES)\
srmmanager.request.switch-to-async-mode-delay.unit=MILLISECONDS

srmmanager.request.get.switch-to-async-mode-delay = ${srmmanager.request.switch-to-async-mode-delay}
(one-of?MILLISECONDS|SECONDS|MINUTES|${srmmanager.request.switch-to-async-mode-delay.unit})\
srmmanager.request.get.switch-to-async-mode-delay.unit = ${srmmanager.request.switch-to-async-mode-delay.unit}

srmmanager.request.bring-online.switch-to-async-mode-delay = ${srmmanager.request.switch-to-async-mode-delay}
(one-of?MILLISECONDS|\
	SECONDS|MINUTES|\
	HOURS|DAYS|\
	${srmmanager.request.switch-to-async-mode-delay.unit})\
srmmanager.request.bring-online.switch-to-async-mode-delay.unit=${srmmanager.request.switch-to-async-mode-delay.unit}

srmmanager.request.put.switch-to-async-mode-delay = ${srmmanager.request.switch-to-async-mode-delay}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srmmanager.request.switch-to-async-mode-delay.unit})\
srmmanager.request.put.switch-to-async-mode-delay.unit=${srmmanager.request.switch-to-async-mode-delay.unit}

srmmanager.request.ls.switch-to-async-mode-delay = ${srmmanager.request.switch-to-async-mode-delay}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srmmanager.request.switch-to-async-mode-delay.unit})\
srmmanager.request.ls.switch-to-async-mode-delay.unit=${srmmanager.request.switch-to-async-mode-delay.unit}

# ---- Maximum advertised poll period for asynchronous requests
#
# Once a schedulable SRM request switches to asynchronous processing (see srmmanager.request.switch-to-async-mode-delay),
# the SRM servers advertises a polling period to the client. The server gradually increases the period every
# time the client polls for the result. This setting places an upper bound on this poll period.
#
# An SRM client is free to ignore the advertised poll period.
#
srmmanager.request.max-poll-period = 60
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)\
srmmanager.request.max-poll-period.unit = SECONDS

srmmanager.request.get.max-poll-period = ${srmmanager.request.max-poll-period}
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS|${srmmanager.request.max-poll-period.unit})\
srmmanager.request.get.max-poll-period.unit = ${srmmanager.request.max-poll-period.unit}

srmmanager.request.put.max-poll-period = ${srmmanager.request.max-poll-period}
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS|${srmmanager.request.max-poll-period.unit})\
srmmanager.request.put.max-poll-period.unit = ${srmmanager.request.max-poll-period.unit}

srmmanager.request.bring-online.max-poll-period = ${srmmanager.request.max-poll-period}
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS|${srmmanager.request.max-poll-period.unit})\
srmmanager.request.bring-online.max-poll-period.unit = ${srmmanager.request.max-poll-period.unit}

srmmanager.request.ls.max-poll-period = ${srmmanager.request.max-poll-period}
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS|${srmmanager.request.max-poll-period.unit})\
srmmanager.request.ls.max-poll-period.unit = ${srmmanager.request.max-poll-period.unit}

srmmanager.request.reserve-space.max-poll-period = ${srmmanager.request.max-poll-period}
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS|${srmmanager.request.max-poll-period.unit})\
srmmanager.request.reserve-space.max-poll-period.unit = ${srmmanager.request.max-poll-period.unit}

srmmanager.request.copy.max-poll-period = ${srmmanager.request.max-poll-period}
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS|${srmmanager.request.max-poll-period.unit})\
srmmanager.request.copy.max-poll-period.unit = ${srmmanager.request.max-poll-period.unit}

# ---- Persistence of requests
#
# Controls whether schedulable SRM requests (put, get, ls, bring online, reserve space) are
# stored in the SRM database.
#
# If disabled, recovery after restart will not work, which will lead to leaked upload
# directories. Listing and monitoring of complete requests are also unsupported if this
# option is disabled.
#
# See also srmmanager.persistence.* for other tuning parameters for request persistence.
#
(one-of?true|false)srmmanager.persistence.enable = true

(one-of?true|false|${srmmanager.persistence.enable})srmmanager.persistence.get.enable = ${srmmanager.persistence.enable}

(one-of?true|false|${srmmanager.persistence.enable})srmmanager.persistence.bring-online.enable = ${srmmanager.persistence.enable}

(one-of?true|false|${srmmanager.persistence.enable})srmmanager.persistence.put.enable = ${srmmanager.persistence.enable}

(one-of?true|false|${srmmanager.persistence.enable})srmmanager.persistence.copy.enable = ${srmmanager.persistence.enable}

(one-of?true|false|${srmmanager.persistence.enable})srmmanager.persistence.ls.enable = ${srmmanager.persistence.enable}

(one-of?true|false|${srmmanager.persistence.enable})srmmanager.persistence.reserve-space.enable = ${srmmanager.persistence.enable}


# ---- Enable cleaning of pending requests during restart
#
# When true and the srm is restarted, all unfinished requests will be aborted right away.
# This will invalidate all ongoing SRM transfers and all ongoing stage requests. If
# false, most clients should not notice a brief restart.
#
(one-of?true|false)srmmanager.persistence.enable.clean-pending-on-restart=false

(one-of?true|false|${srmmanager.persistence.enable.clean-pending-on-restart})\
srmmanager.persistence.get.enable.clean-pending-on-restart = ${srmmanager.persistence.enable.clean-pending-on-restart}

(one-of?true|false|${srmmanager.persistence.enable.clean-pending-on-restart})\
srmmanager.persistence.bring-online.enable.clean-pending-on-restart = ${srmmanager.persistence.enable.clean-pending-on-restart}

(one-of?true|false|${srmmanager.persistence.enable.clean-pending-on-restart})\
srmmanager.persistence.put.enable.clean-pending-on-restart = ${srmmanager.persistence.enable.clean-pending-on-restart}

(one-of?true|false|${srmmanager.persistence.enable.clean-pending-on-restart})\
srmmanager.persistence.copy.enable.clean-pending-on-restart = ${srmmanager.persistence.enable.clean-pending-on-restart}

(one-of?true|false|${srmmanager.persistence.enable.clean-pending-on-restart})\
srmmanager.persistence.ls.enable.clean-pending-on-restart = ${srmmanager.persistence.enable.clean-pending-on-restart}

(one-of?true|false|${srmmanager.persistence.enable.clean-pending-on-restart})\
srmmanager.persistence.reserve-space.enable.clean-pending-on-restart = ${srmmanager.persistence.enable.clean-pending-on-restart}


# ---- Period before old transfers are removed from the database
#
# The srm will hold SRM requests and their history in database for
# srmmanager.persistence.keep-history-period days after that they will be removed.
#
srmmanager.persistence.keep-history-period = 10
(one-of?HOURS|DAYS)srmmanager.persistence.keep-history-period.unit=DAYS

srmmanager.persistence.get.keep-history-period = ${srmmanager.persistence.keep-history-period}
(one-of?HOURS|DAYS|${srmmanager.persistence.keep-history-period.unit})\
srmmanager.persistence.get.keep-history-period.unit=${srmmanager.persistence.keep-history-period.unit}

srmmanager.persistence.bring-online.keep-history-period = ${srmmanager.persistence.keep-history-period}
(one-of?HOURS|DAYS|${srmmanager.persistence.keep-history-period.unit})\
srmmanager.persistence.bring-online.keep-history-period.unit=${srmmanager.persistence.keep-history-period.unit}

srmmanager.persistence.put.keep-history-period = ${srmmanager.persistence.keep-history-period}
(one-of?HOURS|DAYS|${srmmanager.persistence.keep-history-period.unit})\
srmmanager.persistence.put.keep-history-period.unit=${srmmanager.persistence.keep-history-period.unit}

srmmanager.persistence.copy.keep-history-period = ${srmmanager.persistence.keep-history-period}
(one-of?HOURS|DAYS|${srmmanager.persistence.keep-history-period.unit})\
srmmanager.persistence.copy.keep-history-period.unit=${srmmanager.persistence.keep-history-period.unit}

srmmanager.persistence.ls.keep-history-period = ${srmmanager.persistence.keep-history-period}
(one-of?HOURS|DAYS|${srmmanager.persistence.keep-history-period.unit})\
srmmanager.persistence.ls.keep-history-period.unit=${srmmanager.persistence.keep-history-period.unit}

srmmanager.persistence.reserve-space.keep-history-period = ${srmmanager.persistence.keep-history-period}
(one-of?HOURS|DAYS|${srmmanager.persistence.keep-history-period.unit})\
srmmanager.persistence.reserve-space.keep-history-period.unit=${srmmanager.persistence.keep-history-period.unit}


#
# --- How frequently to remove old requests from the database.
#
srmmanager.persistence.remove-expired-period = 600
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)\
srmmanager.persistence.remove-expired-period.unit=SECONDS

srmmanager.persistence.get.remove-expired-period = ${srmmanager.persistence.remove-expired-period}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srmmanager.persistence.remove-expired-period.unit})\
srmmanager.persistence.get.remove-expired-period.unit=${srmmanager.persistence.remove-expired-period.unit}

srmmanager.persistence.bring-online.remove-expired-period = ${srmmanager.persistence.remove-expired-period}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srmmanager.persistence.remove-expired-period.unit})\
srmmanager.persistence.bring-online.remove-expired-period.unit=${srmmanager.persistence.remove-expired-period.unit}

srmmanager.persistence.put.remove-expired-period = ${srmmanager.persistence.remove-expired-period}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srmmanager.persistence.remove-expired-period.unit})\
srmmanager.persistence.put.remove-expired-period.unit=${srmmanager.persistence.remove-expired-period.unit}

srmmanager.persistence.copy.remove-expired-period = ${srmmanager.persistence.remove-expired-period}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|DAYS|\
	${srmmanager.persistence.remove-expired-period.unit})\
srmmanager.persistence.copy.remove-expired-period.unit=${srmmanager.persistence.remove-expired-period.unit}

srmmanager.persistence.ls.remove-expired-period = ${srmmanager.persistence.remove-expired-period}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srmmanager.persistence.remove-expired-period.unit})\
	srmmanager.persistence.ls.remove-expired-period.unit=${srmmanager.persistence.remove-expired-period.unit}

srmmanager.persistence.reserve-space.remove-expired-period = ${srmmanager.persistence.remove-expired-period}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srmmanager.persistence.remove-expired-period.unit})\
srmmanager.persistence.reserve-space.remove-expired-period.unit=${srmmanager.persistence.remove-expired-period.unit}


# ---- Persistence of SRM request transitions
#
# Controls persistence of the transition history of SRM request in the database.
# Request transitions can be examined through the command line interface or
# through the the srmWatch monitoring tool.
#
# Disabling this feature reduces the size and load of the database at the
# expense of not being able to retrieve all information about completed
# transfers. Such information is often useful when diagnosing problems.
#
# If srmmanager.persistence.enable is set to false, this setting has no effect.
#
(one-of?true|false)\
srmmanager.persistence.enable.history = true

(one-of?true|false|${srmmanager.persistence.enable.history})\
srmmanager.persistence.get.enable.history = ${srmmanager.persistence.enable.history}

(one-of?true|false|${srmmanager.persistence.enable.history})\
srmmanager.persistence.bring-online.enable.history = ${srmmanager.persistence.enable.history}

(one-of?true|false|${srmmanager.persistence.enable.history})\
srmmanager.persistence.put.enable.history = ${srmmanager.persistence.enable.history}

(one-of?true|false|${srmmanager.persistence.enable.history})\
srmmanager.persistence.copy.enable.history = ${srmmanager.persistence.enable.history}

(one-of?true|false|${srmmanager.persistence.enable.history})\
srmmanager.persistence.ls.enable.history = ${srmmanager.persistence.enable.history}

(one-of?true|false|${srmmanager.persistence.enable.history})\
srmmanager.persistence.reserve-space.enable.history = ${srmmanager.persistence.enable.history}

# --- Immediately store all transitions
#
# Controls whether intermediate state transitions trigger an update to the database.
# If set to true, every change to a request state is stored. If set to false then
# intermediate state changes are batched together and stored with other changes.
#
# The setting does not control which information is stored in the database. When a
# request is eventually stored, all available information is stored.
#
# If srmmanager.persistence.enable is set to false, this setting has no effect.
#
(one-of?true|false)srmmanager.persistence.enable.store-transient-state = false

(one-of?true|false|${srmmanager.persistence.enable.store-transient-state})\
srmmanager.persistence.get.enable.store-transient-state = ${srmmanager.persistence.enable.store-transient-state}

(one-of?true|false|${srmmanager.persistence.enable.store-transient-state})\
srmmanager.persistence.bring-online.enable.store-transient-state = ${srmmanager.persistence.enable.store-transient-state}

(one-of?true|false|${srmmanager.persistence.enable.store-transient-state})\
srmmanager.persistence.put.enable.store-transient-state = ${srmmanager.persistence.enable.store-transient-state}

(one-of?true|false|${srmmanager.persistence.enable.store-transient-state})\
srmmanager.persistence.copy.enable.store-transient-state = ${srmmanager.persistence.enable.store-transient-state}

(one-of?true|false|${srmmanager.persistence.enable.store-transient-state})\
srmmanager.persistence.ls.enable.store-transient-state = ${srmmanager.persistence.enable.store-transient-state}

(one-of?true|false|${srmmanager.persistence.enable.store-transient-state})\
srmmanager.persistence.reserve-space.enable.store-transient-state = ${srmmanager.persistence.enable.store-transient-state}


# Ls requests settings

# ---- Directory entries to include in list reply
#
# Number of entries allowed to be returnes in a single srmls
# request. Directory listings larger than this most be broken into
# multiple requests.
#
# Use 'infinity' to specify that there is no limit. Warning: Available
# heap memory will be an upper limit as the response cannot be
# streamed. Once heap limit is reached, the SRM will auto-restart.
#
srmmanager.limits.ls.entries = 10000

# ---- List recursion depth
#
# Maximum recursion depth.
#
srmmanager.limits.ls.levels = infinity

# --- Request lifetimes

srmmanager.request.lifetime=14400000
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srmmanager.request.lifetime.unit=MILLISECONDS

srmmanager.request.get.lifetime = ${srmmanager.request.lifetime}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srmmanager.request.lifetime.unit})\
srmmanager.request.get.lifetime.unit=${srmmanager.request.lifetime.unit}

srmmanager.request.bring-online.lifetime = ${srmmanager.request.lifetime}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srmmanager.request.lifetime.unit})\
srmmanager.request.bring-online.lifetime.unit=${srmmanager.request.lifetime.unit}

srmmanager.request.put.lifetime = ${srmmanager.request.lifetime}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srmmanager.request.lifetime.unit})\
srmmanager.request.put.lifetime.unit=${srmmanager.request.lifetime.unit}

srmmanager.request.copy.lifetime = ${srmmanager.request.lifetime}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srmmanager.request.lifetime.unit})\
srmmanager.request.copy.lifetime.unit=${srmmanager.request.lifetime.unit}

# ---- File system root exported by the srm service
srmmanager.root = ${dcache.root}

# Cell address of pnfsmanager service
srmmanager.service.pnfsmanager=${dcache.service.pnfsmanager}

# Timeout for pnfsmanager requests
srmmanager.service.pnfsmanager.timeout = 120
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|DAYS)\
srmmanager.service.pnfsmanager.timeout.unit=SECONDS

# Cell address of gplazma service
srmmanager.service.gplazma=${dcache.service.gplazma}

# Timeout for gplazma requests
srmmanager.service.gplazma.timeout=30000
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srmmanager.service.gplazma.timeout.unit=MILLISECONDS

# gPlazma authorization cache size
srmmanager.service.gplazma.cache.size=1000

# gPlazma authorization cache lifetime
srmmanager.service.gplazma.cache.timeout = 180
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srmmanager.service.gplazma.cache.timeout.unit=SECONDS

# Cell address of spacemanager service
srmmanager.service.spacemanager=${dcache.service.spacemanager}

# Timeout for spacemanager requests
srmmanager.service.spacemanager.timeout=30
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srmmanager.service.spacemanager.timeout.unit=SECONDS

# Cell address of srmmanager service
srmmanager.service.srmmanager = ${dcache.service.srmmanager}

# Timeout for srmmanager requests
srmmanager.service.srmmanager.timeout = 30
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)\
srmmanager.service.srmmanager.timeout.unit = SECONDS

# Cell address of transfermanager service
srmmanager.service.transfermanager=${dcache.service.transfermanager}

# Timeout for transfermanager requests
srmmanager.service.transfermanager.timeout=24
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srmmanager.service.transfermanager.timeout.unit=HOURS

# Cell address of billing service
srmmanager.service.billing = ${dcache.topic.billing}

# Cell address of pinmanager service
srmmanager.service.pinmanager=${dcache.service.pinmanager}

# Timeout for pinmanager requests
srmmanager.service.pinmanager.timeout=60
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srmmanager.service.pinmanager.timeout.unit=MINUTES

# Cell address of poolmanager service
srmmanager.service.poolmanager=${dcache.service.poolmanager}

# Timeout for poolmanager requests
srmmanager.service.poolmanager.timeout = 300
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srmmanager.service.poolmanager.timeout.unit=SECONDS

# Topic to which to publish credential service announcements
srmmanager.credential-service.topic = ${dcache.credential-service.topic}


# ---- Login broker publishing
srmmanager.loginbroker.update-topic= ${dcache.loginbroker.update-topic}
srmmanager.loginbroker.request-topic= ${dcache.loginbroker.request-topic}

# Topic on which to expect pool monitor updates
srmmanager.pool-monitor.topic = ${dcache.pool-monitor.topic}

# ---- Enable automatic creation of directories
#
# Allow automatic creation of directories via srmmanager.
#
#  allow=true, disallow=false
#
(one-of?true|false)srmmanager.enable.recursive-directory-creation = true


# ---- Enable overwrite for SRM
#
# Defines how to respond to write requests to files that already exist.
#
# If srmmanager.enable.overwrite is false, any request to overwrite an existing file will
# be rejected.
#
# If srmmanager.enable.overwrite is enabled, the response depends on whether the SRM v1.1
# or SRM v2.2 interface is used. #For SRM v2.2, the write request contains a flag
# allowing the client to indicate whether it wants an existing file to be overwritten.
# If present, the flag is respected. If not present, the srmmanager.enable.overwrite-by-default
# flag controls whether an existing file is overwritten or not. For SRM v1.1, the write
# request contains no such flag and srmmanager.enable.overwrite-by-default controls whether an
# existing file is overwritten.
#
# Note that setting srmmanager.enable.overwrite to false or srmmanager.enable.overwrite-by-default
# to true violates the SRM 2.2 specification. That is, the defaults are required
# for standards-compliance.
#
(one-of?true|false|${dcache.enable.overwrite})\
srmmanager.enable.overwrite=${dcache.enable.overwrite}
(one-of?true|false)\
srmmanager.enable.overwrite-by-default = false

# ---- Number of concurrent file deletions
#
# To avoid starving other name space operations, the srm throttles
# bulk file deletion. This setting controls the number of concurrent
# file deletion requests submitted to PnfsManager.
#
srmmanager.limits.remove-batch-size = 50

# path to host certificate
srmmanager.authn.hostcert.cert=${dcache.authn.hostcert.cert}

# Host key
srmmanager.authn.hostcert.key=${dcache.authn.hostcert.key}

# Host key refresh interval
srmmanager.authn.hostcert.refresh=${dcache.authn.hostcert.refresh}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${dcache.authn.hostcert.refresh.unit})\
srmmanager.authn.hostcert.refresh.unit=${dcache.authn.hostcert.refresh.unit}

# Path to CA directory
srmmanager.authn.capath=${dcache.authn.capath}

# How often to check the CA certificates for updates
srmmanager.authn.capath.refresh=${dcache.authn.capath.refresh}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${dcache.authn.capath.refresh.unit})\
srmmanager.authn.capath.refresh.unit=${dcache.authn.capath.refresh.unit}

# ---- Certificate Authority Namespace usage mode
(one-of?GLOBUS_EUGRIDPMA|EUGRIDPMA_GLOBUS|GLOBUS|EUGRIDPMA|GLOBUS_EUGRIDPMA_REQUIRE|EUGRIDPMA_GLOBUS_REQUIRE|GLOBUS_REQUIRE|EUGRIDPMA_REQUIRE|EUGRIDPMA_AND_GLOBUS|EUGRIDPMA_AND_GLOBUS_REQUIRE|IGNORE|${dcache.authn.namespace-mode})\
srmmanager.authn.namespace-mode=${dcache.authn.namespace-mode}

# ---- Certificate Revocation List usage mode
(one-of?REQUIRE|IF_VALID|IGNORE|${dcache.authn.crl-mode})\
srmmanager.authn.crl-mode=${dcache.authn.crl-mode}

# ---- On-line Certificate Status Protocol usage mode
(one-of?REQUIRE|IF_AVAILABLE|IGNORE|${dcache.authn.ocsp-mode})\
srmmanager.authn.ocsp-mode=${dcache.authn.ocsp-mode}

# ---- GSI Delegation key pair caching lifetime
srmmanager.authn.gsi.delegation.cache.lifetime = ${dcache.authn.gsi.delegation.cache.lifetime}
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS|${dcache.authn.gsi.delegation.cache.lifetime.unit})\
srmmanager.authn.gsi.delegation.cache.lifetime.unit = ${dcache.authn.gsi.delegation.cache.lifetime.unit}

# ---- Directory for delegated proxy certificates
#
# This is the directory in which the delegated user credentials will
# be stored as files. We recommend set permissions to 700 on this
# directory.
#
srmmanager.user.credentials.directory = @srmUserCredentialsDirectory@

# ---- Database threads
#
# Database updates are queued and their execution is decoupled from
# the execution of SRM requests. The setting controls the number of
# the threads that will be dedicated to execution of these updates.
#
srmmanager.limits.db.threads = 5

# ---- Database request queue depth
#
# Database updates are queued and their execution is decoupled from
# the execution of SRM requests. The setting controls the maximum
# length of the queue.
#
srmmanager.limits.db.queue = 1000

# set graceful shutdown timeout. If set, the internal doStop() method
# will not immediately stop the server. Instead, all Connectors will
# be closed so that new connections will not be accepted and all handlers that
# implement Server.Graceful will be put into the shutdown mode so that no
# new requests will be accepted, but existing requests can complete.
# The server will then wait the configured timeout before stopping.
srmmanager.limits.jetty.graceful-shutdown = 2000
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srmmanager.limits.jetty.graceful-shutdown.unit=MILLISECONDS

# ---- Enable custom address resolution.
#
#   The srmmanager.enable.custom-get-host-by-address property controls
#   whether to try a custom IP resolution if the standard InetAddress
#   method fails. Contributed by BNL.
#
(one-of?true|false)srmmanager.enable.custom-get-host-by-address = false

# ----- Disallowed protocols for get requests
#
# Comma separated list of protocols that will not be used even if both
# client and server support it.
#
srmmanager.protocols.disallowed.get = file,srm

# ----- Disallowed protocols for put requests
#
# Comma separated list of protocols that will not be used even if both
# client and server support it.
#
srmmanager.protocols.disallowed.put = http,file,srm

# ----- Preferred transfer protocols
#
# Ordered comma separated list of preferred transfer protocols. If
# supported by both client and server, protocols early in this list
# will be preferred to protocols later in the list or not in the
# list at all. If no common protocol is found, the first protocol in
# the clients list supported by the server is used.
#
# Setting this property to a non-empty list means the clients protocol
# preference is ignored, which is usually not a good thing. The classic
# use case for this property is as a workaround for clients that assign
# high priority to protocols the server admin tries to avoid.
srmmanager.protocols.preferred =

# ---- Filter doors by tags
#
# Comma separated list of tags. Restricts doors to those that publish
# at least one of these tags.
#
srmmanager.protocols.tags = srm

# ---- Number of doors in random door selection
#
# SRM will order doors according to their load and select certain
# number of the least loaded and then randomly choose which one to
# use.
#
srmmanager.protocols.population-size = 5



# ----- Whether to pin disk files
#
# The SRM protocol allows files to be pinned. The pin suppresses
# automatic garbage collection for the lifetime of the pin.
#
# Since dCache pools may be configured to only serve particular types
# of requests and not every pool may be configured to serve a
# particular read request, strict protocol compliance requires pinning
# even for disk only files.
#
# Often strict protocol compliance is however unnecessary, or disk
# files may be known to always be on read pools. In those cases one
# can skip the pinning step and thus reduce the latency of
# srmPrepareToGet request.
#
# When this property is set to false, files with access latency of
# ONLINE will not be pinned. If all files in the system have access
# latency of ONLINE, then the SRM will not use the pin manager at
# all. Note that when this property is set to false, orphaned file
# location entries in the name space will not validated during the
# srmPrepareToGet processing. The consequence is that the
# srmPrepareToGet may succeed for a lost and the subsequence file
# transfer will fail.
#
(one-of?true|false)srmmanager.enable.pin-online-files = true

# ---- Quality of Service plugins
#
#  dCache SRM supports plugins that allow bandwidth reservation prior
#  to transferring files.  Support for two projects is provide with
#  dCache:  TeraPaths and Lamda Station.
#
#  TeraPaths:
#
#      The TeraPaths project investigates the use and integration of
#      Differentiated Services-based LAN QoS and WAN MPLS technologies
#      in data-intensive distributed computing environments, such as
#      the RHIC/ATLAS computing environment.
#
#      For more details see https://www.racf.bnl.gov/terapaths
#
#      To enable the Terapath plugin define:
#
#      srmmanager.plugins.qos.class = org.dcache.srmmanager.qos.terapaths.TerapathsPlugin
#      srmmanager.plugins.qos.config.file = ${dcache.paths.config}/terapaths.properties
#
#  Lambda Station:
#
#      The Lambda Station project is aimed to enable dynamic
#      allocation of alternate network paths for traffic of production
#      SciDAC applications and to forward designated flows across LAN,
#      negotiates with reservation and provisioning systems of WAN
#      control planes, be it based on SONET channels, demand tunnels,
#      or dynamic circuit networks.
#
#      For more details see http://www.lambdastation.org/
#
#      To enable the Lamda Station plugin define:
#
#      srmmanager.plugins.qos.class = org.dcache.srmmanager.qos.terapaths.LambdaStation
#      srmmanager.plugins.qos.config.file = ${dcache.paths.config}/lambdastation.properties
#
srmmanager.plugins.qos.class =

srmmanager.plugins.qos.config.file =

(one-of?true|false|${dcache.enable.space-reservation})\
srmmanager.enable.space-reservation=${dcache.enable.space-reservation}

#
# ---- Third-party transfers
#
#  Third-party copying is when a client requests that data is sent
#  between this dCache cluster and some other storage system without
#  that client acting as an intermediate for the flow of data.
#
#  With a third-party copy initiatied through the SRM protocol, the
#  client may either specify a protocol-specific endpoint (e.g.,
#  'https://storage.example.org/path/to/remote-file'), or an SRM
#  endpoint (e.g., 'srm://storage.example.org/path/to/remote-file').
#  If an SRM endpoint is specified then dCache will negotiate with the
#  remote server to find the best available transfer protocol.
#
#  dCache will try to verify the integrity of transferred data by
#  comparing locally generated checksum values with that obtained from
#  the remote server.  If the transfer did not use the SRM protocol
#  then checksums can only be obtained via the transfer protocol.
#
#  If the transfer protocol is HTTP then RFC 3230 allows dCache to
#  discover checksums for the remote file.  With this, dCache can
#  learn if the file was corrupted during transfer.  If the remote
#  server supports RFC 3230 and the remote server uses a compatible
#  checksum algorithm then dCache will always verify the data
#  integrity.
#
#  Although dCache supports RFC 3230, most HTTP and WebDAV servers
#  currently do not.  It is also possible that, although the remote
#  server supports RFC 3230, the supplied checksum cannot be used by
#  dCache.  When transferring data with such a server, dCache can
#  either transfer the file's data without checksum verification or
#  fail the request.
#
#  The SRM protocol allows the client to steer the transfer by setting
#  ExtraInfo options.  dCache accepts the 'verify' ExtraInfo option
#  with a value of 'true' or 'false'.  If 'true' then checksum
#  verification is required for the transfers and the failure to
#  obtain a suitable checksum will fail the transfer.  If 'false' then
#  dCache will still attempt to verify data integrety but the transfer
#  will not fail because of dCache was unable to verify the data
#  integrety by checking a checksum.  See SRM client documentation for
#  details on how to set ExtraInfo options.
#
#  If the client leaves this option unspecified then the following
#  property's value is used as a default.
#
(one-of?true|false)srmmanager.enable.third-party.requiring-verification-by-default = true

#
#  Maximum client-assumed average bandwidth
#
#  Certain SRM requests have a lifetime; in particular, for GET, PUT
#  and COPY requests the request lifetime describes for how long files
#  may be transferred.  Given the number of bytes to be transferred,
#  the client is assuming some minimum average bandwidth by specifying
#  a request lifetime.  If the actual average bandwidth is lower than
#  this client-assumed bandwidth then the request will expire during
#  the tranfer.
#
#  dCache does nothing if the lifetime expires during a download (GET)
#  request; however, elapsed lifetimes will result in failed upload
#  requests (PUT) and third-party transfer (COPY) requests.
#
#  Some broken clients have hard-coded, short lifetimes for their
#  requests (e.g., five minutes).  As a consequence, they experience
#  (often sporadic) failures depending on the size of the file(s)
#  involved, the network conditions, and how much IO load the pool is
#  suffering.  This makes such problems difficult to diagnose and the
#  overall service unreliable.
#
#  As a work-around, dCache may be configured to assume some
#  (conservative) estimate of the average bandwidth.  It checks the
#  client-assumed average bandwidth is reasonable; if it is too high
#  (request lifetime is too short) then it increases the request
#  lifetime.  This gives the transfer a reasonable chance of
#  succeeding.
#
#  To enable this work-around, set the configuration property to a
#  very conservative estimate of the average bandwidth, in kiB/s, as
#  an integer.  This should include the effect of both the slowest
#  pool's IO bandwidth and slowest network bandwidth.
#
#  Setting too large a value will result in the work-around being
#  ineffective at protecting dCache against broken clients.  Setting
#  the value too low and transfer slots will remain for longer should
#  a client "disappear" after initialising a transfer.
#
#  A value of 0 switches off this feature.
#
srmmanager.request.maximum-client-assumed-bandwidth = 0

#
#  Time between successive checks for expired requests.
#
#  dCache checks for expired SRM requests in a lazy fashion, by
#  scanning jobs periodically.  This is reasonable since expiration of
#  SRM requests is mostly concerned with garbage-collecting those
#  requests where the client disappeared without terminating correct.
#  We anticipate only a small fraction of SRM requests will require
#  this.
#
#  This property is exposed to allow functional testing; if unsure,
#  leave this property as-is.
#
srmmanager.expired-job-period = 10
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)\
srmmanager.expired-job-period.unit = MINUTES
