#  -----------------------------------------------------------------------
#    Kafka Producer properties
# As it is specified in http://kafka.apache.org/documentation/#producerconfigs
#
#  -----------------------------------------------------------------------

#  ---- Kafka service enabled


#------------------ Non Default properties-----------
#
#These properties do not have default values and must be set.

# If enabled, the various dcache services, like pools and doors will publish messages to
# a Kafka cluster after each transfer. These messages are complementary to billing records.
(one-of?true|false)dcache.enable.kafka = false


# A list of host/port pairs (brokers) to use for establishing the initial connection to the Kafka cluster.
# This list is just used to discover the rest of the brokers in the cluster and should be in the form
# host1:port1,host2:port2,....
dcache.kafka.bootstrap-servers = localhost:9092

# Kafka topic name
dcache.kafka.topic = billing



#--------------------Default Properties------------------------------



dcache.kafka.maximum-block = 1

(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)\
dcache.kafka.maximum-block.unit = SECONDS

#
# KafkaProducer has a set of configurations that are important for tuning the performance of Kafka.
# As it is specified in http://kafka.apache.org/documentation/#producerconfi
# Admins should be able to set them based on their needs.
#
#Thes properties could be set by the help of prefix.

# (prefix)(service).kafka.producer.configs =  Configuration for Kafka Producer,
# for example, you can set  max.block.ms, which is maximum time dCache will spend trying to send an event to the Kafka
# service. If dCache is unable to send the event to Kafka within
# this time limit, the an error is logged and the event is dropped.
#
# (prefix)nfs.kafka.producer.configs =  Configuration for Kafka Producer,
# nfs.kafka.producer.configs!max.block.ms = 1000
# -------------------------------------





# Kafka supports messaging system semantics (message delivery modes).
# 1. At least once semantics - Messages are never lost but may be redelivered.
# 2. At most once semantics -  Messages may be lost but are never redelivered.
# 3. Exactly once semantics -  Message is delivered once and only once.

# 1. At least once semantic
# retries > 0 , retries will introduce duplicates
# ack = default


#2.At most once semantics
# Producer does not retry to send the message when an ack times out or returns an error,
# thus message might end up not being written to the Kafka topic, and hence not delivered to the consumer.

# retries = default
#ack = default


# 3 .Exactly once semantics
#The idempotent producer strengthens Kafka's delivery semantics from at least once to exactly once delivery.
# The producer can only guarantee idempotence for messages sent within a single session.

#retries will no longer introduce duplicates.

#To enable idempotence, set the following properties enable.idempotence=true. If set, the following properties are set:

#enable.idempotence=true
#retries > 0
#acks = all.
#max.in.flight.requests.per.connection = 1
# It is worth noticing, that by default exactly-once processing requires a cluster of at least three brokers what is the recommended setting for production.

#kafka logback appender topic
dcache.log.kafka.topic=alarms

# kafka logback appender level
(not-for-services,one-of?off|error|warn|info|debug|trace|all)dcache.log.level.kafka=off



#Kafka log format
(not-for-services)dcache.log.format.kafka=%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n