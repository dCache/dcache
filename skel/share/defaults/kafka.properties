#  -----------------------------------------------------------------------
#    Kafka Producer properties
# As it is specified in http://kafka.apache.org/documentation/#producerconfigs
#
#  -----------------------------------------------------------------------

#  ---- Kafka service enabled


#------------------ Non Default properties-----------
#
#These properties do not have default values and must be set.

# If enabled, the various dcache services, like pools and doors will publish messages to
# a Kafka cluster after each transfer. These messages are complementary to billing records.
(one-of?true|false)dcache.enable.kafka = false


# A list of host/port pairs (brokers) to use for establishing the initial connection to the Kafka cluster.
# This list is just used to discover the rest of the brokers in the cluster and should be in the form
# host1:port1,host2:port2,....
dcache.kafka.bootstrap-servers = localhost:9092

# Kafka topic name
dcache.kafka.topic = billing

# Optional file from which to load additional Kafka properties for ftp and
# dcap.  For other services, use dcache.kafka.configs.
dcache.kafka.config-file =



#--------------------Default Properties------------------------------

# The configuration controls how long KafkaProducer send method  will block.
# These methods can be blocked either because the buffer is full or metadata unavailable.
# The default value is 60000 in MILLISECONDS.
# it is recommended to use the default value for all services except ftp and dcap, where both dcache.kafka.maximum-block
# and dcache.kafka.maximum-block.unit are used
# You can set the property value for other services with the  help of prefix, which is explained in the next section.
# It is important to understand that Kafka Producer takes  MILLISECONDS as value.

# If metadata is not available Kafka Producer is designed in a way that it blocks send() method for
# up to max.block.ms, which means that this method is not async
# the proposal to improve this has been (KIP-286
# https://cwiki.apache.org/confluence/display/KAFKA/KIP-286%3A+producer.send%28%29+should+not+block+on+metadata+update )
# dropped stating that ; `... the benefit of not having to wait for metadata is probably not worth the complexity added in producer.`
# So it is strongly recommended in case if there is no a reliable Kafka Cluster or you have only one Broker
# the  max.block.ms should be set to lower numbers less than 60 000 (default) is recommended, when you have a use case of big number of
# files being Transferred. If you want complete non-blocking producer.send() can set max.block.ms to 0.

dcache.kafka.maximum-block = 60

(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)\
dcache.kafka.maximum-block.unit = SECONDS

#
# KafkaProducer has a set of configurations that are important for tuning the performance of Kafka.
# As it is specified in http://kafka.apache.org/documentation/#producerconfi
# Admins should be able to set them based on their needs.
#
#Thes properties could be set by the help of prefix.

# (prefix)(service).kafka.producer.configs =  Configuration for Kafka Producer,
# for example, you can set  max.block.ms, which is maximum time dCache will spend trying to send an event to the Kafka
# service. If dCache is unable to send the event to Kafka within
# this time limit, the an error is logged and the event is dropped.
#
# (prefix)nfs.kafka.producer.configs =  Configuration for Kafka Producer,
# nfs.kafka.producer.configs!max.block.ms = 1000
# -------------------------------------





# Kafka supports messaging system semantics (message delivery modes).
# 1. At least once semantics - Messages are never lost but may be redelivered.
# 2. At most once semantics -  Messages may be lost but are never redelivered.
# 3. Exactly once semantics -  Message is delivered once and only once.

# 1. At least once semantic
# retries > 0 , retries will introduce duplicates
# ack = default


#2.At most once semantics
# Producer does not retry to send the message when an ack times out or returns an error,
# thus message might end up not being written to the Kafka topic, and hence not delivered to the consumer.

# retries = default
#ack = default


# 3 .Exactly once semantics
#The idempotent producer strengthens Kafka's delivery semantics from at least once to exactly once delivery.
# The producer can only guarantee idempotence for messages sent within a single session.

#retries will no longer introduce duplicates.

#To enable idempotence, set the following properties enable.idempotence=true. If set, the following properties are set:

#enable.idempotence=true
#retries > 0
#acks = all.
#max.in.flight.requests.per.connection = 1
# It is worth noticing, that by default exactly-once processing requires a cluster of at least three brokers what is the recommended setting for production.

#kafka logback appender topic
dcache.log.kafka.topic=alarms

# kafka logback appender level
(not-for-services,one-of?off|error|warn|info|debug|trace|all)dcache.log.level.kafka=off



#Kafka log format
(not-for-services)dcache.log.format.kafka=%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n