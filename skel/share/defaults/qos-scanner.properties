#  -----------------------------------------------------------------------
#     Default values for qos-verifier
#
#     The qos services are responsible for maintaining the disk and tape
#     requirements of a given file.
#  -----------------------------------------------------------------------
@DEFAULTS_HEADER@

qos-scanner.cell.name=qos-scanner

#  ---- Named queues to consume from
#
#       A service can consume messages from named queues. Other services can
#       write messages to such queues. A named queue has an unqualified cell
#       address, that is, an address without a domain name.
#
#       This property contains a comma separated list of named queues to
#       consume from.
#
qos-scanner.cell.consume = ${qos-scanner.cell.name}

#  ---- Message topics to subscribe to.
#
qos-scanner.cell.subscribe=${qos.pool-monitor-topic}

# ---- Configuration for namespace database connection pool ---------------------------
#

# ---- The maximum number of concurrent database connections
#
#      The recommended minimum setting is the number of scan threads
#      plus a few more for admin calls.
#
#      Since the scanner service shares the chimera database with pnfsmanager,
#      be sure to adjust the postgresql.conf max connections upwards
#      to accommodate both.  Pnfsmanager runs well with about 100
#      connections.  Adding a separate qos service means the
#      connections should be increased by at least the amount below.
#
qos.db.namespace.connections.max=10

# ---- The minimum number of idle database connections.
#
qos.db.namespace.connections.idle=1

(prefix)qos.db.namespace.hikari-properties = Hikari-specific properties

# ---- Database related settings reserved for internal use.
#
qos.db.namespace.host=${chimera.db.host}
qos.db.namespace.name=${chimera.db.name}
qos.db.namespace.user=${chimera.db.user}
qos.db.namespace.password=${chimera.db.password}
qos.db.namespace.password.file=${chimera.db.password.file}
qos.db.namespace.url=${chimera.db.url}
(immutable)qos.db.namespace.schema.changelog=${chimera.db.schema.changelog}
(immutable)qos.db.namespace.schema.auto=false

# ---- Used with the pool scan query. This is a hint given to the jdbc driver
#      to decrease the number of round-trips to the database on large result
#      sets (by default it is 0, meaning ignored).  Setting this too high
#      may, however, adversely affect performance.
#
qos.db.namespace.fetch-size=1000

# ---- Replace with org.dcache.chimera.namespace.ChimeraEnstoreStorageInfoExtractor
#      if you are running an enstore HSM backend.
#
qos.plugins.storage-info-extractor=${dcache.plugins.storage-info-extractor}

# ---- Thread queues --------------------------------------------------------------
#

# ---- Thread queue used to handle responses from the verifier.  These
#      involve batched counts, and the amount of update work done on the
#      thread is small.  Should mirror the bulk threads on the verifier.
#
qos.limits.scanner.submit-threads=8

# ---- Thread queue used for scanning the namespace on pool state changes or
#      as part of a periodic check.  Requires a database connection,
#      which it holds onto for the life of the task being executed.
#
#      A note on pool operation throttling:
#
#      A pool scan or processing of a pool status message can generate
#      thousands, even millions, of file tasks.  Allowing too many pool
#      operations to run simultaneously can, aside from the increased
#      pressure on the namespace database, potentially overload the system.
#      Lowering the number of available threads may be necessary
#      if the number of files per pool is on the order of 2 million or
#      greater (or, alternately, one may need to increase the memory of the
#      JVM for the scanner service).
#
qos.limits.scanner.task-threads=5

qos.limits.scanner.pool-op-init-grace-period=5
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)qos.limits.scanner.pool-op-init-grace-period.unit=MINUTES

# ---- Pool Status update handling.
#
#      How long to wait between the reception of a pool down update
#      and actually launching a scan operation to check replicas on
#      that pool.  Setting to 0 will trigger the scan immediately.
#
qos.limits.scanner.down-grace-period=1
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)qos.limits.scanner.down-grace-period.unit=HOURS

# ---- Pool Status update handling.
#
#      How long to wait between the reception of a pool restart update
#      and actually launching a scan operation to check replicas on
#      that pool. Setting to 0 will trigger the scan immediately.
#
qos.limits.scanner.restart-grace-period=6
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)qos.limits.scanner.restart-grace-period.unit=HOURS

# ---- Pool Status update handling.
#
#      How long to allow a pool scan operation which is running to wait to be updated.
#      When this window expires, the scan will be canceled.
#
qos.limits.scanner.pool-op-max-idle-time=1
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)qos.limits.scanner.pool-op-max-idle-time.unit=HOURS

# ---- Periodic system scanning
#
#      For the rationale for the system scanning types, see further in The Book.
#
#      The following properties control the periodic scanning to check
#      for qos consistency and initiate any adjustments that may be necessary
#      in the case of inconsistent state.
#
#      The scan period refers to the default amount of time between sweeps to check for timeouts.
#
#      The scan windows refer to the amount of time between scheduled periodic
#      system diagnostic scans.
#
#      QOS NEARLINE refers to files whose QoS policy is defined and whose RP is NEARLINE CUSTODIAL.
#
#      ONLINE refers to scans of all files with persistent copies, whether
#      or not they are REPLICA or CUSTODIAL, but for which a policy is not defined.
#      ONLINE scanning is done by a direct query to the namespace, and is batched
#      into requests determined by the batch size.  Unlike with resilience, this
#      kind of scan will only touch each inode entry once (whereas pool scans may overlap
#      when multiple replicas are involved).
#
#      On the other hand, a general pool scan will only look at files on pools that are
#      currently IDLE and UP, so those that are excluded or (temporarily) unattached
#      will be skipped.   This avoids generating a lot of alarms concerning files without
#      disk copies that should exist.
#
#      The direct ONLINE scan is enabled by default.  To use the pool scan instead, disable
#      "online" either via the property or the admin reset command.  Be aware, however, that
#      unlike resilience, all pools will be scanned, not just those in the resilient/primary
#      groups; thus the online window should be set to accommodate the amount of time it
#      will take to cycle through the entire set of pools this way. Needless to say, doing
#      a direct ONLINE scan probably will take less time than a general pool scan.
#
#      The batch size for a direct ONLINE scan is lowered to serve as an implicit backgrounding or
#      de-prioritization (since the scan is done in batches, this allows for preemption by
#      QOS scans if they are running concurrently).
#
qos.limits.scanner.scan-period=3
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)qos.limits.scanner.scan-period.unit=MINUTES
qos.limits.scanner.qos-nearline-window=12
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)qos.limits.scanner.qos-nearline-window.unit=HOURS
qos.limits.scanner.enable.online-scan=true
qos.limits.scanner.online-window=2
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)qos.limits.scanner.online-window.unit=DAYS
qos.limits.scanner.qos-nearline-batch-size=500000
qos.limits.scanner.online-batch-size=200000
